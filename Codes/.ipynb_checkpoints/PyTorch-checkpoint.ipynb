{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "data=pd.read_csv(\"../Data/creditcard.csv\")\n",
    "del data['Time']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1516db9705bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# create a stochastic gradient descent optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;31m# create a loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "#separate X and Y\n",
    "X=data.iloc[:,0:-1].values\n",
    "Y=data.iloc[:,-1].values\n",
    "\n",
    "#Normalize data\n",
    "min_max_scaler=preprocessing.MinMaxScaler()\n",
    "X=min_max_scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "#Separate train/Test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=230)\n",
    "\n",
    "batch_size=30\n",
    "epochs=2\n",
    "learning_rate=0.001\n",
    "\n",
    "\n",
    "#Training data set tensors\n",
    "train_target = torch.tensor(y_train.astype(np.long))\n",
    "train = torch.tensor(X_train.astype(np.float32)) \n",
    "train_tensor = torch.utils.data.TensorDataset(train, train_target) \n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_tensor, batch_size = 16, shuffle = True)\n",
    "\n",
    "#test dataset tensors\n",
    "test_target = torch.tensor(y_test.astype(np.long))\n",
    "test = torch.tensor(X_test.astype(np.float32)) \n",
    "test_tensor = torch.utils.data.TensorDataset(train, train_target) \n",
    "test_loader = torch.utils.data.DataLoader(dataset = train_tensor, batch_size = 16, shuffle = True)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(29, 6)\n",
    "        self.fc2 = nn.Linear(6, 2)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "# create a stochastic gradient descent optimizer\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "# create a loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# run the main training loop\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (Xdata, target) in enumerate(train_loader):\n",
    "        Xdata, target = Variable(Xdata), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        net_out = net(Xdata)\n",
    "        loss = criterion(net_out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    out = net(test)\n",
    "    _,predicted = torch.max(out.data,1)\n",
    "    total = test_target.size(0)\n",
    "    correct = (predicted==test_target).sum().item()\n",
    "    print('Epoch #',epoch+1,\"  \",'Accuracy: {} %'.format(100 * correct / total))\n",
    "    print (\"---------------------\")\n",
    "\n",
    "#Save Model\n",
    "torch.save(net, \"../SavedModels/Torch_Model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and make a prediction\n",
    "\n",
    "#define initial structure\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(29, 6)\n",
    "        self.fc2 = nn.Linear(6, 2)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return torch.sigmoid(x)\n",
    "net = Net()\n",
    "\n",
    "#read the model\n",
    "model = torch.load(\"../SavedModels/Torch_Model.pt\") \n",
    "\n",
    "#Make a sample input tensor\n",
    "row=torch.tensor(np.array([[-1.35980713e+00, -7.27811733e-02,  2.53634674e+00,  1.37815522e+00,\n",
    "       -3.38320770e-01,  4.62387778e-01,  2.39598554e-01,  9.86979013e-02,\n",
    "        3.63786970e-01,  9.07941720e-02, -5.51599533e-01, -6.17800856e-01,\n",
    "       -9.91389847e-01, -3.11169354e-01,  1.46817697e+00, -4.70400525e-01,\n",
    "        2.07971242e-01,  2.57905802e-02,  4.03992960e-01,  2.51412098e-01,\n",
    "       -1.83067779e-02,  2.77837576e-01, -1.10473910e-01,  6.69280749e-02,\n",
    "        1.28539358e-01, -1.89114844e-01,  1.33558377e-01, -2.10530535e-02,\n",
    "        1.49620000e+02]]).astype(np.float32))\n",
    "#Make predictions\n",
    "out = model(row)\n",
    "_,predicted = torch.max(out.data,1)\n",
    "\n",
    "#convert prediction from tensor to numpy array\n",
    "predicted=predicted.numpy()\n",
    "\n",
    "\n",
    "print (predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
